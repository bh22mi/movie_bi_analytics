{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708586c9-d00e-4e4c-9fae-5b0837cb548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_movie_clean.csv saved.\n"
     ]
    }
   ],
   "source": [
    "#Clean movies_metadata.csv\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load movie dataset\n",
    "df = pd.read_csv(r'/Users/bhoomikaharkhani/Downloads/movie_dataset/movies_metadata.csv', low_memory = False)\n",
    "\n",
    "# Keep relevant columns\n",
    "df = df[['id', 'title', 'genres', 'release_date', 'runtime', 'vote_average', 'vote_count']]\n",
    "\n",
    "# Remove non-numeric IDs\n",
    "df = df[df['id'].apply(lambda x: str(x).isdigit())]\n",
    "df['movie_id'] = df['id'].astype(int)\n",
    "\n",
    "# Extract first genre from JSON-like string\n",
    "def extract_genre(genre_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)\n",
    "        return genres[0]['name'] if genres else none\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['genre'] = df['genres'].apply(extract_genre)\n",
    "\n",
    "# Convert release date to datetime\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "\n",
    "# Rename columns and select final ones\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        'title':'movie_name',\n",
    "        'runtime':'duration_mins',\n",
    "        'vote_average':'average_rating',\n",
    "        'vote_count':'rating_count'\n",
    "    })\n",
    "\n",
    "df = df[['movie_id', 'movie_name', 'genre', 'release_date', 'duration_mins', 'average_rating', 'rating_count']]\n",
    "\n",
    "# Save cleaned file\n",
    "df.to_csv('dim_movie_clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0b9e06-b614-4c17-8f0d-2640ba276bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ fact_rating_clean.csv saved.\n"
     ]
    }
   ],
   "source": [
    "#Clean ratings_small.csv\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load ratings dataset\n",
    "ratings = pd.read_csv(r'/Users/bhoomikaharkhani/Downloads/movie_dataset/ratings_small.csv', low_memory = False)\n",
    "\n",
    "# Convert timestamp to date\n",
    "ratings['date'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "\n",
    "# Add rating_id (auto increment)\n",
    "ratings.insert(0, 'rating_id', range(1, len(ratings) + 1))\n",
    "\n",
    "# Select required columns\n",
    "fact_rating = ratings[['rating_id', 'movieId', 'userId', 'date', 'rating']]\n",
    "fact_rating = fact_rating.rename(columns={\n",
    "    'movieId': 'movie_id',\n",
    "    'userId': 'user_id'\n",
    "})\n",
    "\n",
    "# Save\n",
    "fact_rating.to_csv('fact_rating_clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573470a5-39d2-4d7b-8c67-55695e9e03e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dim_user.csv saved.\n"
     ]
    }
   ],
   "source": [
    "#Create dim_user.csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Get unique user_ids from ratings\n",
    "user_ids = ratings['userId'].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Simulate additional user details\n",
    "dim_user = pd.DataFrame()\n",
    "dim_user['user_id'] = user_ids\n",
    "dim_user['user_name'] = user_ids.apply(lambda x: f'User_{x}')\n",
    "dim_user['gender'] = np.random.choice(['Male', 'Female'], size = len(user_ids))\n",
    "dim_user['country'] = np.random.choice(['USA','India','UK','Germany'], size=len(user_ids))\n",
    "\n",
    "dim_user.to_csv('dim_user.csv', index=False)\n",
    "print(\"✅ dim_user.csv saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cc40fb-ff41-44e6-9219-59f299e625fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dim_date.csv saved.\n"
     ]
    }
   ],
   "source": [
    "# Extract unique dates from ratings\n",
    "unique_dates = pd.to_datetime(fact_rating['date'].unique())\n",
    "dim_date = pd.DataFrame()\n",
    "dim_date['date'] = unique_dates\n",
    "dim_date['year'] = dim_date['date'].dt.year\n",
    "dim_date['month'] = dim_date['date'].dt.month\n",
    "dim_date['month_name'] = dim_date['date'].dt.strftime('%B')\n",
    "dim_date['quarter'] = dim_date['date'].dt.quarter.apply(lambda q: f'Q{q}')\n",
    "dim_date['week_number'] = dim_date['date'].dt.isocalendar().week\n",
    "\n",
    "dim_date.to_csv('dim_date.csv', index=False)\n",
    "print(\"✅ dim_date.csv saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231e2201-3a02-4425-9235-58b9ea6f1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dim_date.csv saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dim_date.csv\")\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date  # Adjust column name\n",
    "df = df.drop_duplicates(subset='date')\n",
    "df.to_csv(\"dim_date_clean.csv\", index=False)\n",
    "print(\"✅ dim_date.csv saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
